{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(messages_filepath, categories_filepath):\n",
    "    '''\n",
    "       INPUT:\n",
    "           messages_filepath (str): messages csv files path\n",
    "           categories_filepath (str): categories csv file path\n",
    "       OUTPUT:\n",
    "           df: dataframe having messages and cateries details joined\n",
    "       DESCRIPTION:\n",
    "               read messages csv file as messages dataframe and\n",
    "               categories csv file as categories dataframe\n",
    "               merge both the dataframes as df applying inner join on ['id'] column\n",
    "    '''\n",
    "\n",
    "    df_messages = pd.read_csv(messages_filepath, encoding='latin-1')\n",
    "    df_categories = pd.read_csv(categories_filepath, encoding='latin-1')\n",
    "\n",
    "    # merge datasets\n",
    "    df = pd.merge(df_messages, df_categories, how='inner', on='id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    '''\n",
    "       INPUT:\n",
    "          The function takes the dataframe as merges from 'load_data' and re-creates a columns from the data\n",
    "          while dropping the category column.\n",
    "          arg: dataframe\n",
    "       OUTPUT:\n",
    "           df: dataframe having messages and cateries details\n",
    "    '''\n",
    "\n",
    "   # create a dataframe of the each of the category type\n",
    "    categories = df.categories.str.split(';', expand=True)\n",
    "\n",
    "    # select the first row of the categories in the dataframe\n",
    "    row = categories.iloc[0, :]\n",
    "\n",
    "    # convert the row cells to columns using lambda expression.\n",
    "    cols = row.apply(lambda x: x[:-2])\n",
    "\n",
    "    # bind new columns to the `categories` dataframe.\n",
    "    categories.columns = cols\n",
    "\n",
    "    # convert category values to numbers 0 or 1\n",
    "    for column in categories:\n",
    "        # set each value to be the last character of the string\n",
    "        categories[column] = categories[column].apply(lambda x: x[-1])\n",
    "\n",
    "        # convert column from string to numeric\n",
    "        categories[column] = pd.to_numeric(categories[column])\n",
    "\n",
    "    df = df.drop('categories', axis=1)  # drop the original categories column from df\n",
    "    df = pd.concat([df, categories], axis=1)\n",
    "\n",
    "    df = df.drop_duplicates()  # drop the duplicates\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, database_filename):\n",
    "    '''\n",
    "    INPUT:\n",
    "        cleansed dataframe having messages and their belonging categories details\n",
    "    OUTPUT: \n",
    "        database having Messages table\n",
    "    DESCRIPTION:\n",
    "        Insert dataframe into sql table<DisasterMessages> in database file to be used as input   \n",
    "    '''\n",
    "    table = 'DisasterMessages'\n",
    "\n",
    "    engine = create_engine('sqlite:///{}'.format(database_filename))\n",
    "    \n",
    "\n",
    "    df.to_sql(name=table, con=engine,if_exists='replace', chunksize=10, index=False) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "        df = load_data('./data/disaster_messages.csv','./data/disaster_categories.csv')\n",
    "\n",
    "        print('Cleaning data...')\n",
    "        df = clean_data(df)\n",
    "        print('Saving data...')\n",
    "        save_data(df, 'DisasterResponse.db')\n",
    "        \n",
    "        print('Cleaned data saved to database!')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "Saving data...\n",
      "Cleaned data saved to database!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python process_data.py disaster_messages.csv disaster_categories.csv DisasterResponse.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
